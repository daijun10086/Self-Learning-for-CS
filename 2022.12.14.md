# CS61B
## A) Asymptotics I
In order to compare different algotirhms' efficiency, we have two ways to measure it.

- Runing time
- Operation number

Using running time is easy to understand and straightforward, but it has some cons:

- it is related to the specific machine you running the program
- it is not easy to get result is the input scale is quite large.

And for the second way, we count the number of differet operations, it indeed have no relation with the machine you running the program, but it is tedius and not rigourous in mathematics. Also, for different input scale, the answer is different, it need repeated computation.

## B) Big Theta
Suppose we have a function $R(N)$ with order of growth $f(N)$. In Big Theta notation, we write this as $R(N)\in\Theta(f(N))$. Some examples just list below:

1. $N^{3} + 3N^{4}\in\Theta(N^{4})$
2. $11N + N^{3}\in\Theta(N^{3})$
3. $40sin(N) + 4N^{2}\in\Theta(N^{2})$

### Formal Definition
$R(N)\in\Theta(f(N))$ means that there exists positive constants $k_{1}$ and $k_{2}$ such that: $k_{1} \cdot f(N) \leq R(N) \leq k_{2} \cdot f(N)$, for all values of $N$ greater than $N_{0}$

## C) Big O
Earlier, we used Big Theta to describe the order of growth of functions as well as code pieces. On the other hand, Big O can be though of as a runtime inequality, namely, as "less than or equal".

Briefly speaking, **Big Theta** means verify both the upper and lower bound of the running time, but **Big O** only verify the upper bound of the running time. We can draw the conclusion from the below examples:

- $N^{3} + 3 \cdot N^{4} \in\ O(N^{4})$
- $N^{3} + 3 \cdot N^{4} \in\ O(N^{6})$
- $N^{3} + 3 \cdot N^{4} \in\ O(N!)$

### Formal Definition
$R(N)\in\ O(f(N))$ means that there exists $k_{1}$ such that $R(N) \leq k_{1} \cdot f(N)$ for every value of N greater than $N_{0}$.

Observe that this is a looser condition than Big Theta since Big O does not care about the lower bound.
