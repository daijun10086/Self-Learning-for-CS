# CS61B
## A) Binary Search
Binary search is a nice way of searching a list for a particular item. It requires the list to be in sorted order, and uses that fact to find an element quickly.

In order to use binary search, we should sort the list, and everytime we just need to cheek the middle element of the sorted list if it is the desired element. If Yes, mission done! If not, we should change the low and upper bound for search.

## B) Merge Sort
First, let's remind ourselves of selection sort, which we will initially use as a building block for merge sort.

Selection sort works off two basic steps:

- Find the smallest item among the unsorted items, and move it to the front, and 'fix' it in the place.
- Sort remaining unsorted items using selection sort.

And if we analyse the running time of selection sort, it is $\Theta(N^{2})$.

An important idea: **Arbitary unit of time**, since different machine have different running time even through it is exactly same program. Thus, it is hard to compare two algorithm using absolute time, like nanoseconds... So we adopt a new idea, Arbitary Unit of Time, it is a relative time concept, so we can using how much arbiary unit of time needed to compare different algorithms.

This is the essense of **merge sort:**

- if the list size is 1, return, otherwise:
- Mergesort the left half
- Mergesort the right half
- Merge the result.

Breifly speaking, merge sort is using more merge operation than selection sort operation as possible. Because merge operation is $\Theta(N)$, but the selection sort is $\Theta(N^{2})$, if we use more merge operation can decrease running time effectively.

And the ultimate Big Theta of merge sorting is $N\log(N)$.

## C) Amortized Analysis
A more rigorous examination of amortized analysis is done here, in three steps:

- Pick a cost model
- Compute the average cost of i-th operation
- Show that this average (amortized) cost is bounded by a constant.

## D) Problem about Analyzing Running Time
![](Screenshot%202022-12-16%20at%2018.25.55.png)

This problem is tricky, the first time I try to solve it, I give the answer:

- Best case: $\Theta(1)$
- Worst case: $\Theta(N\cdot (M + 1))$

Unfortunely, it is totally wrong, the correct answer is:

- Best case: $\Theta(N)$
- Worst case: $\Theta(M + N)$

The reason for that is *break* statement only jump out for one iteration loop, in this case means that only escape from the inner *for loop*, so the running time is $\Theta(N)$. For the worst case, the trick is *j* is initialize in the outer scope of *for loop*, it will lead to the first i loop finish the j will be **M**, and stay put, which means that in the left *N - 1* loop, the j always be M, thus the running time for the worst case is $\Theta(N + M)$.